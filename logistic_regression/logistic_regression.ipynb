{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef8c945-6021-408d-a571-6e0dd3af7073",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a903568b-3359-425c-aeb6-bff86477e512",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "1. From linear combinations to predicting the probability.\n",
    "2. How to find coefficients $\\theta$? Maximum likelihood.\n",
    "3. Gradient descent implementation\n",
    "4. Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157bcfeb-5bc0-4675-bcaa-26adc9462f87",
   "metadata": {},
   "source": [
    "### Linear combinations >> probability\n",
    "\n",
    "The idea is similar to Linear Regression - use $X*\\theta$ for prediction. But now we say that we want to predict the probability - the value $P(y | X) \\in [0 ... 1]$\n",
    "\n",
    "$$\n",
    "P(y = 1|x;\\theta) = h_\\theta(x) \\\\\n",
    "P(y = 0|x;\\theta) = 1 - h_\\theta(x)\n",
    "$$\n",
    "\n",
    "We need some $g(\\theta^T * X)$\n",
    "$$\n",
    "h_\\theta(X) = g(\\theta^T * X) = g(z), \\text{ where } z = \\theta^T * X \\in [-\\infty ... +\\infty]\\\\\n",
    "$$\n",
    "In other words, we need:\n",
    "$$\n",
    "\\theta^T * X \\in [-\\infty ... +\\infty] =>> P(y | X) \\in [0 ... 1]\n",
    "$$\n",
    "\n",
    "- transform $\\theta^T * X$ into $[0 ... 1]$\n",
    "- or find some $f(P)$ that returns $[-\\infty ... +\\infty]$ and derive $P(y | X)$ from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27330f35-ccf7-4608-8393-c393cd196524",
   "metadata": {},
   "source": [
    "### Odds and log(odds)\n",
    "\n",
    "$$\n",
    "P(y = 1|x;\\theta) = h_\\theta(x) \\in [0 ... 1]\\\\\n",
    "Odds(y = 1) = \\frac {P(y = 1)} {P(y = 0)} = \\frac {P(y = 1)} {1 - P(y = 1)}  \\in [0 ... +\\infty] \\\\\n",
    "\\log{Odds(y = 1)} = \\log{\\frac {P(y = 1)} {1 - P(y = 1)}} \\in [-\\infty ... +\\infty]\n",
    "$$\n",
    "We found a function $f(P)$ that returns values $[-\\infty ... +\\infty]$. So, now we can make aт assumption that\n",
    "$$\n",
    "\\theta^T * X = \\log{\\frac {P(y = 1)} {1 - P(y = 1)}} \\\\\n",
    "$$\n",
    "Then:\n",
    "$$\n",
    "P(y = 1 | X; \\theta) = h_\\theta(X) = \\frac {1} {1 + e^{-(\\theta^T * X)}}\n",
    "$$\n",
    "\n",
    "Now the question is - how to find the best $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a635e0d2-e48f-44fa-b57e-3bb1e7b54bee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Likelihood\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{For } y = 1: p(y|x,\\theta) = h_\\theta(x) \\\\\n",
    "\\text{For } y = 0: p(y|x,\\theta) = 1 - h_\\theta(x) \\\\\n",
    "$$\n",
    "Same thing with one formula:\n",
    "$$\n",
    "p(y|x,\\theta) = (h_\\theta(x))^y (1 - h_\\theta(x))^{1 - y} \\\\ \n",
    "p(y|x,\\theta) = (\\frac {1} {1 + e^{-(\\theta^T * X)}})^y (1 - \\frac {1} {1 + e^{-(\\theta^T * X)}})^{1 - y}\n",
    "$$\n",
    "\n",
    "We need the most likely parameters theta. The LIKELIHOOD of parametrs $\\theta$ is basically the same as the probability of y but with $\\theta$ as a variable. Probability of all y values is the product of all probabilities (joint probability).\n",
    "\n",
    "$$\n",
    "L(\\theta) = p(\\vec{y}|X;\\theta) \\\\\n",
    "= \\prod_{i=1}^{n} p(y^{(i)}|x^{(i)};\\theta) \\\\\n",
    "= \\prod_{i=1}^{n} (h_\\theta(x^{(i)}))^{y^{(i)}} (1 - h_\\theta(x^{(i)}))^{1 - y^{(i)}} \\\\\n",
    "= \\prod_{i=1}^{n} (\\frac {1} {1 + e^{-(\\theta * x^{(i)})}})^y (1 - \\frac {1} {1 + e^{-(\\theta * x^{(i)})}})^{1 - y}\n",
    "$$\n",
    "\n",
    "Logistic function is monotonic, which allows us to maximize the logarythm of this product. We replace Linelihood with LOG of Likelihood. Then PRODUCT will transform to SUMM.\n",
    "\n",
    "$$\n",
    "l(\\theta) = \\log L(\\theta) \\\\\n",
    "= \\sum_{i=1}^n y^{(i)} \\log h(x^{(i)}) + (1 - y^{(i)})log(1 - h(x^{(i)}) \\\\\n",
    "= \\sum_{i=1}^n y^{(i)} \\log \\frac {1} {1 + e^{-(\\theta * x^{(i)})}} + (1 - y^{(i)})log(1 - \\frac {1} {1 + e^{-(\\theta * x^{(i)})}}) \\\\\n",
    "$$\n",
    "\n",
    "But now the value depends on the dataset size - sum from 1 to n. So, for convenience we need to scale the whole equation:\n",
    "\n",
    "$$\n",
    "l(\\theta) = \\frac{1}{n} * \\sum_{i=1}^n y^{(i)} \\log \\frac {1} {1 + e^{-(\\theta * x^{(i)})}} + (1 - y^{(i)})log(1 - \\frac {1} {1 + e^{-(\\theta * x^{(i)})}}) \\\\\n",
    "$$\n",
    "\n",
    "And this thing we want to maximize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8938ccb-4344-4ed2-9f99-a05376e732ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Derivative of Likelihood function\n",
    "\n",
    "In advance we can say:\n",
    "\n",
    "$$\n",
    "g(z) = \\frac{1}{1 + e^{-z}} \\\\\n",
    "$$\n",
    "Derivative of a fraction of two functions\n",
    "$$\n",
    "\\frac{d}{dz} g(z) = \\frac{d}{dz} \\frac{1}{f(z)} = \\\\\n",
    "= \\frac{0 * (1 + e^{-z}) - 1 * \\frac{d}{dz} (1 + e^{-z}) )}{(1 + e^{-z})^2} = \\\\\n",
    "= \\frac{-(-e^{-z})}{(1 + e^{-z})^2} = \\frac{e^{-z} + 1 - 1}{(1 + e^{-z})^2} = \\\\\n",
    "= (1 - \\frac{1}{1 + e^{-z}}) * \\frac{1}{1 + e^{-z}} = \\\\\n",
    "= g(z) * (1 - g(z)) \\\\\n",
    "$$\n",
    "Coming back to $h_{\\theta}(x)$ we need to add $\\frac{dz}{dx} = \\frac{d\\theta^T*X}{dx} = X$ to the end\n",
    "$$\n",
    "\\text{1. } \\frac {\\partial{}} {\\partial{\\theta}} h_\\theta(X) = h_\\theta(X) * (1 - h_\\theta(X)) * X = \\frac {1} {1 + e^{-(\\theta^T * X)}} * (1 - \\frac {1} {1 + e^{-(\\theta^T * X)}}) * X \\\\\n",
    "\\text{2. } \\frac {\\partial{}} {\\partial{\\theta}} \\log{h_\\theta(X)} = \\frac{1}{h_\\theta(X)} * h_\\theta(X) * (1 - h_\\theta(X) * X) = (1 - h_\\theta(X)) * X \\\\\n",
    "\\text{3. } \\frac {\\partial{}} {\\partial{\\theta}} \\log{\\left(1 - h_\\theta(X) \\right)} = \\frac{1}{1 - h_\\theta(X)} * \\left[ 0 - h_\\theta(X) * (1 - h_\\theta(X)) * X \\right]  =  \\\\\n",
    "= \\frac{1}{1 - h_\\theta(X)} * 0 - \\frac{1}{1 - h_\\theta(X)} * h_\\theta(X) * (1 - h_\\theta(X)) * X = \\\\\n",
    "= - h_\\theta(X) * X\\\\\n",
    "$$\n",
    "\n",
    "Finally:\n",
    "\n",
    "$$\n",
    "\\frac {\\partial{}} {\\partial{\\theta}} l(\\theta) = \\frac{1}{n} * \\sum_{i = 1}^{n} X * \\left( y^{(i)} - h_\\theta(X) \\right) = \\frac{1}{n} * \\sum_{i = 1}^{n} X * \\left( y^{(i)} - \\frac {1} {1 + e^{-(\\theta * x^{(i)})}} \\right)\n",
    "$$\n",
    "\n",
    "Gradient solution:\n",
    "\n",
    "$$\n",
    "\\theta := \\theta + \\alpha * \\frac {\\partial{}} {\\partial{\\theta}} l(\\theta) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f05464-ecfe-45db-881f-f09061755284",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "Works the same as for Linear Regression:\n",
    "\n",
    "$$\n",
    "\\text{old l}(\\theta) = \\frac{1}{n} * \\sum_{i=1}^n y^{(i)} \\log \\frac {1} {1 + e^{-(\\theta * x^{(i)})}} + (1 - y^{(i)})log(1 - \\frac {1} {1 + e^{-(\\theta * x^{(i)})}}) \\\\\n",
    "\\text{new l}(\\theta) = \\text{old l}(\\theta) + \\lambda * ||\\theta||_k^k\n",
    "$$\n",
    "\n",
    "For k=2:\n",
    "$$\n",
    "\\text{new l}(\\theta) = \\text{old l}(\\theta) + \\lambda * ||\\theta||_2^2 \\\\\n",
    "\\frac {\\partial{}} {\\partial{\\theta}} \\text{new l}(\\theta) = \\frac {\\partial{}} {\\partial{\\theta}} \\text{old l}(\\theta) + 2 * \\lambda * \\theta = \\\\\n",
    "= \\frac{1}{n} * \\sum_{i = 1}^{n} X * \\left( y^{(i)} - \\frac {1} {1 + e^{-(\\theta * x^{(i)})}} \\right) + 2 * \\lambda * \\theta\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta := \\theta + \\alpha * \\frac {\\partial{}} {\\partial{\\theta}} \\text{new l}(\\theta) = \\\\\n",
    "\\theta := \\theta + \\alpha * \\left( \\frac{1}{n} * \\sum_{i = 1}^{n} X * \\left( y^{(i)} - \\frac {1} {1 + e^{-(\\theta * x^{(i)})}} \\right) + 2 * \\lambda * \\theta \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c5727-4968-4c6f-9e64-ee79769d4b54",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d68aa1-e2eb-450a-9689-ded445513e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58332e86-a2ff-4eac-8006-11799a81107e",
   "metadata": {},
   "source": [
    "I'll be using Spaceship Titanic dataset from [Kaggle competition](https://www.kaggle.com/competitions/spaceship-titanic)\n",
    "\n",
    "Data description:\n",
    "* PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "* HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "* CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "* Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "* Destination - The planet the passenger will be debarking to.\n",
    "* Age - The age of the passenger.\n",
    "* VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
    "* RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "* Name - The first and last names of the passenger.\n",
    "* Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36140b7f-43cb-4cc9-a906-33eef696cabc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/spaceship_titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13c757d1-7309-4be9-83ac-13a4cf61ac81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "...           ...        ...           ...     ...     ...                ...   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "...           ...  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ce745f1-eaf6-48e4-9084-1ffddcd00741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.69947548 -0.28543451 -0.28469585 -0.26876547 -0.27612744]\n",
      " [ 1.         -0.33398833 -0.27998983 -0.24397213 -0.22947464  0.20090496]\n",
      " [ 1.          2.00852964  1.87791977 -0.28469585 -0.22500978  5.55861321]\n",
      " [ 1.          0.28608996  0.49073538  0.31964411 -0.09642163  2.6164789 ]\n",
      " [ 1.         -0.88516903 -0.24308698 -0.0387246  -0.26697952  0.21480755]]\n",
      "[0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "X = data[['Age', 'FoodCourt', 'ShoppingMall', 'VRDeck', 'Spa']]\n",
    "X = X.dropna()\n",
    "y = data['Transported']\n",
    "y = y[X.index].astype('int').values\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "ones = np.ones(len(X))[:, None]\n",
    "X = np.concatenate([ones, X], axis=1)\n",
    "\n",
    "print(X[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "106283d0-f7ea-47c9-8e50-bd28c7a0a6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thetas: [-1.5329799  -1.27043347  2.51789466  0.32548171 -7.48842278 -8.14083801]\n",
      "Accuracy: 0.6844583036745429\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogRegression:\n",
    "    def __init__(self, alpha=0.01, n_iterations=1000):\n",
    "        self.alpha = alpha\n",
    "        self.n_iterations = n_iterations\n",
    "        return\n",
    "    \n",
    "    def hypothesis(self, theta, X):\n",
    "        return 1 / (1 + np.exp(-theta @ X.T))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        hypothesis = self.hypothesis(self.theta, X)\n",
    "        errors = y - hypothesis\n",
    "        grad = X.T @ errors\n",
    "        self.theta += self.alpha * grad\n",
    "        \n",
    "        for _ in range(self.n_iterations):\n",
    "            hypothesis = self.hypothesis(self.theta, X)\n",
    "            errors = y - hypothesis\n",
    "            grad = X.T @ errors / len(X)\n",
    "            self.theta += self.alpha * grad\n",
    "        return self.theta\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.hypothesis(self.theta, X)\n",
    "    \n",
    "    \n",
    "model = LogRegression(alpha=0.01, n_iterations=1000)\n",
    "thetas = model.fit(X, y)\n",
    "predictions_proba = model.predict(X)\n",
    "predictions = np.where(predictions_proba > 0.5, 1, 0)\n",
    "\n",
    "print(f'Thetas: {thetas}')\n",
    "print(f'Accuracy: {balanced_accuracy_score(y, predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2536cf6-57f8-4cec-8278-50467ce9167e",
   "metadata": {},
   "source": [
    "With regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "178181e4-4023-4f0d-a741-7dbd8dcc9080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thetas: [-1.58048501 -1.47775439  2.76464137  0.36479095 -8.29152851 -9.01096115]\n",
      "Accuracy: 0.6823934189000977\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogRegressionL2:\n",
    "    def __init__(self, alpha=0.01, n_iterations=1000, c=0):\n",
    "        self.alpha = alpha\n",
    "        self.n_iterations = n_iterations\n",
    "        self.lmbd = c\n",
    "        return\n",
    "    \n",
    "    def hypothesis(self, theta, X):\n",
    "        return 1 / (1 + np.exp(-theta @ X.T))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        hypothesis = self.hypothesis(self.theta, X)\n",
    "        errors = y - hypothesis\n",
    "        grad = X.T @ errors\n",
    "        self.theta += self.alpha * grad\n",
    "        \n",
    "        for _ in range(self.n_iterations):\n",
    "            dummy_theta = self.theta.copy()\n",
    "            dummy_theta[0] = 0\n",
    "            hypothesis = self.hypothesis(self.theta, X)\n",
    "            errors = y - hypothesis\n",
    "            grad = X.T @ errors / len(X)\n",
    "            self.theta += self.alpha * (grad + self.lmbd * dummy_theta)\n",
    "        return self.theta\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.hypothesis(self.theta, X)\n",
    "    \n",
    "    \n",
    "model = LogRegressionL2(alpha=0.01, n_iterations=1000, c=0.01)\n",
    "thetas = model.fit(X, y)\n",
    "predictions_proba = model.predict(X)\n",
    "predictions = np.where(predictions_proba > 0.5, 1, 0)\n",
    "\n",
    "print(f'Thetas: {thetas}')\n",
    "print(f'Accuracy: {balanced_accuracy_score(y, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aabfef-4118-46aa-823d-d04e869ba285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
